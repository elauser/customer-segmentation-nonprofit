{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the database and save the data\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "\n",
    "with duckdb.connect(database='../data/database.duckdb', read_only=False) as con:\n",
    "    # Use this to open and close the connection, so that the database is not locked\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_number                    int64\n",
       "gender                            object\n",
       "date_of_birth             datetime64[ns]\n",
       "postcode                          object\n",
       "count2015                          int64\n",
       "sum2015                          float64\n",
       "merchandise2015                    int64\n",
       "count2016                          int64\n",
       "sum2016                          float64\n",
       "merchandise2016                    int64\n",
       "count2017                          int64\n",
       "sum2017                          float64\n",
       "merchandiese2017                   int64\n",
       "count2018                          int64\n",
       "sum2018                          float64\n",
       "merchandiese2018                   int64\n",
       "count2019                          int64\n",
       "sum2019                          float64\n",
       "merchandise2019                    int64\n",
       "lastpaymentdate           datetime64[ns]\n",
       "penultimatepaymentdate    datetime64[ns]\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First we load the data into a pandas dataframe, just what we are used to.\n",
    "# We can do the same just with Duckdb though but it shows nicely how well Duckdb works with Pandas.\n",
    "df = pd.read_csv(\n",
    "    '../data/ground-truth/data.csv', \n",
    "    sep=\";\", \n",
    "    decimal=',', \n",
    "    low_memory=False,\n",
    "    parse_dates=['LastPaymentDate', 'PenultimatePaymentDate', 'Date of Birth'], \n",
    "    dayfirst=True\n",
    ")\n",
    "df.columns = df.columns.str.replace(' ', '_').str.lower()\n",
    "df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'female', None, None, 0, 0.0, 0, 0, 0.0, 0, 0, 0.0, 0, 0, 0.0, 0, 1, 4.5, 0, datetime.datetime(2019, 12, 18, 0, 0), None, None)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Customers with added age column\n",
    "with duckdb.connect(database='../data/database.duckdb', read_only=False) as con:\n",
    "    con.execute(\"\"\"\n",
    "        CREATE OR REPLACE TABLE customers AS (\n",
    "            SELECT \n",
    "                *,\n",
    "                STRING_SPLIT(\n",
    "                    CAST((CURRENT_DATE() - date_of_birth) / 365 AS STRING), \n",
    "                    ' '\n",
    "                )[1]::INTEGER as age, \n",
    "            FROM df)\n",
    "    \"\"\")\n",
    "    con.execute(\"\"\"\n",
    "        SELECT * FROM customers LIMIT 1\n",
    "    \"\"\")\n",
    "    print(con.fetchall())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(7, 1)]\n"
     ]
    }
   ],
   "source": [
    "# In hindsight, this is not the best way to do this. Just create the whole table and let superset slice and dice the data.\n",
    "create_age_distribution = \"\"\"\n",
    "CREATE OR REPLACE TABLE age_distribution AS (\n",
    "  WITH age AS (\n",
    "      SELECT\n",
    "          STRING_SPLIT(\n",
    "              CAST((CURRENT_DATE() - date_of_birth) / 365 AS STRING), \n",
    "              ' '\n",
    "          )[1]::INTEGER as age,\n",
    "      FROM df\n",
    "      WHERE age is not NULL\n",
    "  )\n",
    "  SELECT\n",
    "      age,\n",
    "      count(*) AS count,\n",
    "  FROM age\n",
    "  GROUP BY age\n",
    "  ORDER BY age asc\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "with duckdb.connect(database='../data/database.duckdb', read_only=False) as con:\n",
    "    con.execute(create_age_distribution)\n",
    "    con.execute(\"\"\"\n",
    "        SELECT * FROM age_distribution LIMIT 1\n",
    "    \"\"\")\n",
    "    print(con.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Lost Champions', None, 307201, 4, 4, 1, 'female', None, '1210', 2, 7.5, 0, 1, 10.0, 0, 0, 0.0, 0, 2, 10.5, 0, 0, 0.0, 0, datetime.datetime(2018, 11, 9, 0, 0), datetime.datetime(2018, 11, 8, 0, 0), 28.0, 5, datetime.timedelta(days=461))]\n"
     ]
    }
   ],
   "source": [
    "create_rfc_quantiles = \"\"\"\n",
    "CREATE OR REPLACE TABLE rfc_quantiles AS (\n",
    "    WITH summary_data AS (\n",
    "        SELECT\n",
    "            customer_number,\n",
    "            sum(sum2015 + sum2016 + sum2017 + sum2018 + sum2019) AS total_sum,\n",
    "            sum(count2015 + count2016 + count2017 + count2018 + count2019) AS total_count,\n",
    "            (SELECT MAX(lastpaymentdate) from df) - lastpaymentdate AS days_since_last_payment,\n",
    "        FROM df\n",
    "        GROUP BY customer_number, lastpaymentdate\n",
    "    ),\n",
    "    quantiles AS (\n",
    "        SELECT\n",
    "            customer_number,\n",
    "            quantile(total_sum, 0.25) AS total_sum_1,\n",
    "            quantile(total_sum, 0.5) AS total_sum_2,\n",
    "            quantile(total_sum, 0.75) AS total_sum_3,\n",
    "            quantile(total_count, 0.25) AS total_count_1,\n",
    "            quantile(total_count, 0.5) AS total_count_2,\n",
    "            quantile(total_count, 0.75) AS total_count_3,\n",
    "            quantile(days_since_last_payment, 0.25) AS days_since_last_payment_1,\n",
    "            quantile(days_since_last_payment, 0.5) AS days_since_last_payment_2,\n",
    "            quantile(days_since_last_payment, 0.75) AS days_since_last_payment_3,\n",
    "        FROM summary_data\n",
    "        GROUP BY customer_number\n",
    "    ),\n",
    "    quantile_binned AS (\n",
    "        SELECT\n",
    "            quantiles.customer_number,\n",
    "            CASE\n",
    "                WHEN total_sum < total_sum_1 THEN 1\n",
    "                WHEN total_sum < total_sum_2 THEN 2\n",
    "                WHEN total_sum < total_sum_3 THEN 3\n",
    "                ELSE 4\n",
    "            END AS monetary_quantile,\n",
    "            CASE\n",
    "                WHEN total_count < total_count_1 THEN 1\n",
    "                WHEN total_count < total_count_2 THEN 2\n",
    "                WHEN total_count < total_count_3 THEN 3\n",
    "                ELSE 4\n",
    "            END AS frequency_quantile,\n",
    "            -- Reversed the order of the quantiles for recency\n",
    "            CASE\n",
    "                WHEN days_since_last_payment < days_since_last_payment_1 THEN 4\n",
    "                WHEN days_since_last_payment < days_since_last_payment_2 THEN 3\n",
    "                WHEN days_since_last_payment < days_since_last_payment_3 THEN 2\n",
    "                ELSE 1\n",
    "            END AS recency_quantile,\n",
    "        FROM quantiles \n",
    "        JOIN summary_data ON (quantiles.customer_number = summary_data.customer_number)\n",
    "    )\n",
    "    SELECT\n",
    "        CASE\n",
    "            WHEN monetary_quantile >= 4 AND frequency_quantile >= 4 AND recency_quantile >= 4 THEN 'Champions'\n",
    "            WHEN monetary_quantile >= 4 AND frequency_quantile >= 4 AND recency_quantile <= 1 THEN 'Lost Champions'\n",
    "            WHEN monetary_quantile >= 3 AND frequency_quantile >= 3 AND recency_quantile >= 3 THEN 'Loyal Customers'\n",
    "            WHEN monetary_quantile >= 3 AND frequency_quantile >= 2 AND recency_quantile >= 4 THEN 'Potential Loyalists'\n",
    "            WHEN monetary_quantile >= 2 AND frequency_quantile >= 1 AND recency_quantile >= 4 THEN 'New Customers'\n",
    "            WHEN monetary_quantile >= 2 AND frequency_quantile >= 1 AND recency_quantile >= 3 THEN 'Promising'\n",
    "            WHEN monetary_quantile >= 2 AND frequency_quantile >= 1 AND recency_quantile >= 2 THEN 'Hibernating'\n",
    "            WHEN monetary_quantile >= 1 AND frequency_quantile >= 1 AND recency_quantile >= 1 THEN 'Lost'\n",
    "        END AS customer_segment,\n",
    "        STRING_SPLIT(\n",
    "            CAST((CURRENT_DATE() - date_of_birth) / 365 AS STRING), \n",
    "            ' '\n",
    "        )[1]::INTEGER as age,\n",
    "        *\n",
    "    FROM quantile_binned\n",
    "    LEFT JOIN df USING (customer_number)\n",
    "    LEFT JOIN summary_data USING (customer_number)\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "with duckdb.connect(database='../data/database.duckdb', read_only=False) as con:\n",
    "    con.execute(create_rfc_quantiles)\n",
    "    con.execute(\"\"\"\n",
    "        SELECT * FROM rfc_quantiles LIMIT 1\n",
    "    \"\"\")\n",
    "    print(con.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 64-bit ('3.8.13-schallanalyse')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cede99f64a1207939459ebd2a83217fa322a342595588c1f5703156d238958d6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
